{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data import *\n",
    "import h5py \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def levenstein_distance(word1, word2):\n",
    "    m, n = len(word1), len(word2)\n",
    "\n",
    "    matrix = torch.zeros((m+1, n+1), dtype=int)\n",
    "\n",
    "    matrix[:, 0] = torch.arange(m+1)\n",
    "    matrix[0, :] = torch.arange(n+1)\n",
    "\n",
    "    for i in range(1, m+1):\n",
    "        for j in range(1, n+1):\n",
    "            if word1[i-1] == word2[j-1]:\n",
    "                substitution_cost = 0\n",
    "            else:\n",
    "                substitution_cost = 1\n",
    "\n",
    "            matrix[i, j] = min(\n",
    "                matrix[i-1, j] + 1,                # deletion\n",
    "                matrix[i, j-1] + 1,                # insertion\n",
    "                matrix[i-1, j-1] + substitution_cost    # substitution\n",
    "            )\n",
    "\n",
    "    similarity = 1 - matrix[m, n] / max(m, n)\n",
    "    similarity_percentage = similarity * 100\n",
    "\n",
    "    return similarity_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip      =      Flip(probability = 0)\n",
    "shufflen  =  Shufflebylength(probability = 0,segment_length = 24)\n",
    "intrashot = IntraShotShuffle(probability = 0)\n",
    "intershot = ShuffleShots(probability = 0)\n",
    "neighbourshot = ShuffleNeighbourShots(probability = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TVSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset = h5py.File(os.path.join('Data\\\\h5datasets','eccv16_dataset_tvsum_google_pool5'+'.h5'),'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average Levenstein distance for flip: 0.15411686897277832\n",
      "Levenstein distance variance for flip: 0.025596522909040686\n"
     ]
    }
   ],
   "source": [
    "levenstein_distances = []\n",
    "for index_in_question in video_dataset:\n",
    "    original_video = torch.arange(0,len(video_dataset[index_in_question]['gtscore'][...]))\n",
    "    levenstein_distances.append(levenstein_distance(original_video,flip.shuffle(original_video,original_video)[0]).item())\n",
    "print(f' Average Levenstein distance for flip: {np.mean(levenstein_distances)}')\n",
    "print(f'Levenstein distance variance for flip: {np.var(levenstein_distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intrashot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\LocalSum\\Data\\dataloader.py:213: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  for shot_bound in torch.asarray(shot_boundaries):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Levenstein distance for intrashot: 100.0\n",
      "Levenstein distance variance for intrashot: 100.0\n"
     ]
    }
   ],
   "source": [
    "levenstein_distances = []\n",
    "for index_in_question in video_dataset:\n",
    "    shot_boundaries = video_dataset[index_in_question]['downsampled_shot_boundaries']\n",
    "    shuffled_scores = []\n",
    "    original_video = torch.arange(0,len(video_dataset[index_in_question]['gtscore'][...]))\n",
    "    for i in range (3):\n",
    "            shuffled_scores.append(levenstein_distance(original_video,intrashot.shuffle(original_video,original_video,shot_bounds = shot_boundaries)[0]).item())\n",
    "    levenstein_distances.append(np.mean(shuffled_scores))\n",
    "print(f'Average Levenstein distance for intrashot: {np.mean(levenstein_distances)}')\n",
    "print(f'Levenstein distance variance for intrashot: {np.mean(levenstein_distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Levenstein distance for intrashot: 58.513739242553704\n",
      "Levenstein distance variance for neighbourshot: 23.627426546520663\n"
     ]
    }
   ],
   "source": [
    "levenstein_distances = []\n",
    "for index_in_question in video_dataset:\n",
    "    shot_boundaries = video_dataset[index_in_question]['downsampled_shot_boundaries']\n",
    "    shuffled_scores = []\n",
    "    original_video = torch.arange(0,len(video_dataset[index_in_question]['gtscore'][...]))\n",
    "    for i in range (3):\n",
    "            shuffled_scores.append(levenstein_distance(original_video,neighbourshot.shuffle(original_video,original_video,shot_bounds = shot_boundaries)[0]).item())\n",
    "    levenstein_distances.append(np.mean(shuffled_scores))\n",
    "print(f'Average Levenstein distance for intrashot: {np.mean(levenstein_distances)}')\n",
    "print(f'Levenstein distance variance for neighbourshot: {np.var(levenstein_distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intershot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenstein distance for intershot: 6.439960781733195\n",
      "Levenstein distance variance for intershot: 13.740797710901138\n"
     ]
    }
   ],
   "source": [
    "levenstein_distances = []\n",
    "for index_in_question in video_dataset:\n",
    "    shot_boundaries = video_dataset[index_in_question]['downsampled_shot_boundaries']\n",
    "    shuffled_scores = []\n",
    "    original_video = torch.arange(0,len(video_dataset[index_in_question]['gtscore'][...]))\n",
    "    for i in range (3):\n",
    "            shuffled_scores.append(levenstein_distance(original_video,intershot.shuffle(original_video,original_video,shot_bounds = shot_boundaries)[0]).item())\n",
    "    levenstein_distances.append(np.mean(shuffled_scores))\n",
    "print(f'Levenstein distance for intershot: {np.mean(levenstein_distances)}')\n",
    "print(f'Levenstein distance variance for intershot: {np.var(levenstein_distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenstein distance for segments: 11.030543835957841\n",
      "Levenstein distance variance for segments: 33.42716896825168\n"
     ]
    }
   ],
   "source": [
    "levenstein_distances = []\n",
    "for index_in_question in video_dataset:\n",
    "    shot_boundaries = video_dataset[index_in_question]['downsampled_shot_boundaries']\n",
    "    shuffled_scores = []\n",
    "    original_video = torch.arange(0,len(video_dataset[index_in_question]['gtscore'][...]))\n",
    "    for i in range (3):\n",
    "        shuffled_scores.append(levenstein_distance(original_video,shufflen.shuffle(original_video,original_video)[0]).item())\n",
    "    levenstein_distances.append(np.mean(shuffled_scores))\n",
    "print(f'Levenstein distance for segments: {np.mean(levenstein_distances)}')\n",
    "print(f'Levenstein distance variance for segments: {np.var(levenstein_distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SumMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset = h5py.File(os.path.join('Data\\\\h5datasets','eccv16_dataset_summe_google_pool5'+'.h5'),'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average Levenstein distance for flip: 0.19608044624328613\n",
      "Levenstein distance variance for flip: 0.06055240414093532\n"
     ]
    }
   ],
   "source": [
    "levenstein_distances = []\n",
    "for index_in_question in video_dataset:\n",
    "    original_video = torch.arange(0,len(video_dataset[index_in_question]['gtscore'][...]))\n",
    "    levenstein_distances.append(levenstein_distance(original_video,flip.shuffle(original_video,original_video)[0]).item())\n",
    "print(f' Average Levenstein distance for flip: {np.mean(levenstein_distances)}')\n",
    "print(f'Levenstein distance variance for flip: {np.var(levenstein_distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IntraShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Levenstein distance for intrashot: 100.0\n",
      "Levenstein distance variance for intrashot: 0.0\n"
     ]
    }
   ],
   "source": [
    "levenstein_distances = []\n",
    "for index_in_question in video_dataset:\n",
    "    shot_boundaries = video_dataset[index_in_question]['downsampled_shot_boundaries']\n",
    "    shuffled_scores = []\n",
    "    original_video = torch.arange(0,len(video_dataset[index_in_question]['gtscore'][...]))\n",
    "    for i in range (3):\n",
    "            shuffled_scores.append(levenstein_distance(original_video,intrashot.shuffle(original_video,original_video,shot_bounds = shot_boundaries)[0]).item())\n",
    "    levenstein_distances.append(np.mean(shuffled_scores))\n",
    "print(f'Average Levenstein distance for intrashot: {np.mean(levenstein_distances)}')\n",
    "print(f'Levenstein distance variance for intrashot: {np.var(levenstein_distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Levenstein distance for neighboursshot: 59.71926767985026\n",
      "Levenstein distance variance for neighbourshot: 50.702490501236724\n"
     ]
    }
   ],
   "source": [
    "levenstein_distances = []\n",
    "for index_in_question in video_dataset:\n",
    "    shot_boundaries = video_dataset[index_in_question]['downsampled_shot_boundaries']\n",
    "    shuffled_scores = []\n",
    "    original_video = torch.arange(0,len(video_dataset[index_in_question]['gtscore'][...]))\n",
    "    for i in range (3):\n",
    "            shuffled_scores.append(levenstein_distance(original_video,neighbourshot.shuffle(original_video,original_video,shot_bounds = shot_boundaries)[0]).item())\n",
    "    levenstein_distances.append(np.mean(shuffled_scores))\n",
    "print(f'Average Levenstein distance for neighboursshot: {np.mean(levenstein_distances)}')\n",
    "print(f'Levenstein distance variance for neighbourshot: {np.var(levenstein_distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intershot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenstein distance for intershot: 13.229750630060833\n",
      "Levenstein distance variance for intershot: 106.09865319315887\n"
     ]
    }
   ],
   "source": [
    "levenstein_distances = []\n",
    "for index_in_question in video_dataset:\n",
    "    shot_boundaries = video_dataset[index_in_question]['downsampled_shot_boundaries']\n",
    "    shuffled_scores = []\n",
    "    original_video = torch.arange(0,len(video_dataset[index_in_question]['gtscore'][...]))\n",
    "    for i in range (3):\n",
    "            shuffled_scores.append(levenstein_distance(original_video,intershot.shuffle(original_video,original_video,shot_bounds = shot_boundaries)[0]).item())\n",
    "    levenstein_distances.append(np.mean(shuffled_scores))\n",
    "print(f'Levenstein distance for intershot: {np.mean(levenstein_distances)}')\n",
    "print(f'Levenstein distance variance for intershot: {np.var(levenstein_distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenstein distance for segments: 18.79139928181966\n",
      "Levenstein distance variance for segments: 110.29835594223745\n"
     ]
    }
   ],
   "source": [
    "levenstein_distances = []\n",
    "for index_in_question in video_dataset:\n",
    "    shot_boundaries = video_dataset[index_in_question]['downsampled_shot_boundaries']\n",
    "    shuffled_scores = []\n",
    "    original_video = torch.arange(0,len(video_dataset[index_in_question]['gtscore'][...]))\n",
    "    for i in range (3):\n",
    "        shuffled_scores.append(levenstein_distance(original_video,shufflen.shuffle(original_video,original_video)[0]).item())\n",
    "    levenstein_distances.append(np.mean(shuffled_scores))\n",
    "print(f'Levenstein distance for segments: {np.mean(levenstein_distances)}')\n",
    "print(f'Levenstein distance variance for segments: {np.var(levenstein_distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-learning",
   "language": "python",
   "name": "video-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
