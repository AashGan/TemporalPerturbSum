{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VASNET with PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = [1,2,3]\n",
    "dataset = 'tvsum'\n",
    "model = 'AttentionPC'\n",
    "setting = 'tran'\n",
    "name = f'Baseline_{setting}'\n",
    "config_path = os.path.join('Configs/Baseline',model,setting)\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.7},'Shufflebylength':{\"probability\":0.7,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 5e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": {}\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGLSUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SumMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = [1,2,3]\n",
    "dataset = 'summe'\n",
    "model = 'PGL_SUM'\n",
    "setting = 'tran'\n",
    "name = f'Baseline_{setting}'\n",
    "config_path = os.path.join('Configs/Baseline',model,setting)\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.7},'Shufflebylength':{\"probability\":0.7,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 3,\n",
    "        \"learning_rate\": 5e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": {}\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = [1,2,3]\n",
    "dataset = 'tvsum'\n",
    "model = 'PGL_SUM'\n",
    "setting = 'can'\n",
    "name = f'Combined_{setting}'\n",
    "config_path = os.path.join('Configs\\\\Data_Augmentations_deter',model,setting)\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.0},'Shufflebylength':{\"probability\":0.0,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_deter_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 5e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": shuff_len_flip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = [1,2,3]\n",
    "dataset = 'summe'\n",
    "model = 'PGL_SUM'\n",
    "setting = 'aug'\n",
    "name = f'Combined_{setting}'\n",
    "config_path = os.path.join('Configs/Baseline',model,setting)\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.7},'Shufflebylength':{\"probability\":0.7,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 3,\n",
    "        \"learning_rate\": 5e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": shuff_len_flip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = [1,2,3]\n",
    "dataset = 'tvsum'\n",
    "model = 'TransformerSum'\n",
    "setting = 'can'\n",
    "gradnorm_clip = 2\n",
    "params = {'input_dims' : 1024,'transformer_dims' : 512,'feedforward_dims':1024*2,'pos_enc':['absolute',None],'dropout'  :  0.6,'enable_scale':True,'depth':2,'heads':[4,8],'causal_mask':True,'mask_params':[(48,0.05),(96,0.05)],'skip_linear':False,'skip_att':False}\n",
    "name = f\"Combined_{params['pos_enc'][0]}_{setting}\"\n",
    "config_path = os.path.join('Configs/Data_Augmentations',model,setting)\n",
    "\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.7},'Shufflebylength':{\"probability\":0.7,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 2e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model,'params': params\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": shuff_len_flip,\n",
    "        \"gradnorm_clip\":gradnorm_clip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'Configs\\\\Ablation-Study\\\\Scaling'\n",
    "trial_number = [1,2,3]\n",
    "dataset = 'summe'\n",
    "model = 'TransformerSum'\n",
    "setting = 'can'\n",
    "gradnorm_clip = 2\n",
    "params = {'input_dims' : 1024,'transformer_dims' : 512,'feedforward_dims':1024*2,'pos_enc':['absolute',None],'dropout'  :  0.5,'enable_scale':False,'depth':2,'heads':[4,8],'causal_mask':True,'mask_params':[(24,0.1),(48,0.1)],'skip_linear':True,'skip_att':False}\n",
    "name = f\"Scaling_expt_scale_{params['enable_scale']}_{setting}\"\n",
    "\n",
    "\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.7},'Shufflebylength':{\"probability\":0.7,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 2e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model,'params': params\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": {},\n",
    "        \"gradnorm_clip\":gradnorm_clip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'Configs\\\\Ablation-Study\\\\NoPos'\n",
    "trial_number = [1,2,3]\n",
    "dataset = 'summe'\n",
    "model = 'TransformerSum'\n",
    "setting = 'can'\n",
    "gradnorm_clip = 2\n",
    "params = {'input_dims' : 1024,'transformer_dims' : 512,'feedforward_dims':1024*2,'pos_enc':[None,None],'dropout'  :  0.5,'enable_scale':False,'depth':1,'heads':[8],'causal_mask':False,'mask_params':[(24,0.1)],'skip_linear':True,'skip_att':False}\n",
    "name = f\"No_pos_expt_{setting}\"\n",
    "\n",
    "\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.7},'Shufflebylength':{\"probability\":0.7,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 2e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model,'params': params\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": {},\n",
    "        \"gradnorm_clip\":gradnorm_clip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'Configs\\\\Ablation-Study\\\\depth'\n",
    "trial_number = [1,2,3]\n",
    "dataset = 'summe'\n",
    "model = 'TransformerSum'\n",
    "setting = 'can'\n",
    "depth = 3\n",
    "gradnorm_clip = 2\n",
    "params = {'input_dims' : 1024,'transformer_dims' : 512,'feedforward_dims':1024*2,'pos_enc':['absolute',None,None],'dropout'  :  0.5,'enable_scale':True,'depth':depth,'heads':[8,8,8],'causal_mask':True,'mask_params':[(48,0.1),(48,0.1),(48,0.1)],'skip_linear':False,'skip_att':False}\n",
    "name = f\"Depth_expt_depth_{params['depth']}_{setting}\"\n",
    "\n",
    "\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.7},'Shufflebylength':{\"probability\":0.7,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 2e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model,'params': params\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": {},\n",
    "        \"gradnorm_clip\":gradnorm_clip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'Configs\\\\Ablation-Study\\\\FinalModel'\n",
    "trial_number = [1,2,3]\n",
    "dataset = 'summe'\n",
    "model = 'TransformerSum'\n",
    "setting = 'can'\n",
    "depth = 2\n",
    "gradnorm_clip = 2\n",
    "params = {'input_dims' : 1024,'transformer_dims' : 512,'feedforward_dims':1024*2,'pos_enc':['absolute',None],'dropout'  :  0.4,'enable_scale':True,'depth':depth,'heads':[4,8],'causal_mask':True,'mask_params':[(48,0.1),(96,0.1)],'skip_linear':False,'skip_att':False}\n",
    "name = f\"Final_model_3_{setting}\"\n",
    "\n",
    "\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.5},'Shufflebylength':{\"probability\":0.5,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 2e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model,'params': params\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": shuff_len_flip,\n",
    "        \"gradnorm_clip\":gradnorm_clip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'Configs\\\\Proposed_model\\\\WithAug'\n",
    "trial_number = [1,2,3]\n",
    "dataset = 'tvsum'\n",
    "model = 'TransformerSum'\n",
    "setting = 'can'\n",
    "depth = 2\n",
    "gradnorm_clip = 2\n",
    "params = {'input_dims' : 1024,'transformer_dims' : 512,'feedforward_dims':1024*2,'pos_enc':['absolute',None],'dropout'  :  0.4,'enable_scale':True,'depth':depth,'heads':[4,8],'causal_mask':True,'mask_params':[(48,0.1),(96,0.1)],'skip_linear':False,'skip_att':False}\n",
    "name = f\"Proposed_model_aug_{setting}\"\n",
    "\n",
    "\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.5},'Shufflebylength':{\"probability\":0.5,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 2e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model,'params': params\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": shuff_len_flip,\n",
    "        \"gradnorm_clip\":gradnorm_clip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'Configs\\\\Proposed_model\\\\AugSum'\n",
    "trial_number = [1,2,3]\n",
    "dataset = 'summe'\n",
    "model = 'TransformerSum'\n",
    "setting = 'can'\n",
    "gradnorm_clip = 2\n",
    "params = {'input_dims' : 1024,'transformer_dims' : 512,'feedforward_dims':1024*2,'pos_enc':['absolute',None,None],'dropout'  :  0.4,'enable_scale':True,'depth':3,'heads':[4,8,8],'causal_mask':True,'mask_params':[[48,0.1],[96,0.1],[]],'skip_linear':False,'skip_att':False}\n",
    "name = f\"Proposed_model_aug_summe_{setting}\"\n",
    "\n",
    "\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.5},'Shufflebylength':{\"probability\":0.5,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 2e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model,'params': params\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": shuff_len_flip,\n",
    "        \"gradnorm_clip\":gradnorm_clip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'Configs\\\\Ablation-Study\\\\FinalModel'\n",
    "trial_number = [1,2,3]\n",
    "dataset = 'summe'\n",
    "model = 'TransformerSum'\n",
    "setting = 'can'\n",
    "depth = 2\n",
    "gradnorm_clip = 2\n",
    "params = {'input_dims' : 1024,'transformer_dims' : 512,'feedforward_dims':1024*2,'pos_enc':['absolute',None],'dropout'  :  0.4,'enable_scale':True,'depth':depth,'heads':[4,8],'causal_mask':True,'mask_params':[(48,0.1),(96,0.1)],'skip_linear':False,'skip_att':False}\n",
    "name = f\"Final_model_3_{setting}\"\n",
    "\n",
    "\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.5},'Shufflebylength':{\"probability\":0.5,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 2e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model,'params': params\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": shuff_len_flip,\n",
    "        \"gradnorm_clip\":gradnorm_clip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = [1,2,3]\n",
    "dataset = 'tvsum'\n",
    "model = 'Attention'\n",
    "setting = 'tran'\n",
    "name = f'Baseline_{setting}'\n",
    "config_path = os.path.join('Configs/MLPExpt',model,setting)\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Flip':{\"probability\":0.7},'Shufflebylength':{\"probability\":0.7,'segment_length':24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 5e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": {},\n",
    "        \"batch\" : 128\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = [1,2,3]\n",
    "dataset = 'summe'\n",
    "model = 'VASNetPC'\n",
    "setting = 'can'\n",
    "aug_type = 'Shufflebylength'\n",
    "name = f'{aug_type}_low_prob_{setting}'\n",
    "config_path = os.path.join(f'Configs/ShuffleExperiments//{aug_type}//24',setting)\n",
    "for trial in trial_number:\n",
    "    shuff_len_flip = {'Shufflebylength':{\"probability\":0.7,\"segment_length\": 24}}\n",
    "    config_dict = {\n",
    "        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "        \"save_name\": f\"{name}_{trial}\",\n",
    "        \"reg\": 1e-05,\n",
    "        \"num_epochs\": 50,\n",
    "        \"learning_rate\": 5e-05,\n",
    "        \"Model_params\": {\n",
    "            \"Model\": model\n",
    "        },\n",
    "        \"loss_function\" : \"MSE\",\n",
    "        \"total_splits\": 5,\n",
    "        \"data_aug\": shuff_len_flip\n",
    "    }\n",
    "    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "    with open(path_save,'w') as json_file:\n",
    "        json.dump(config_dict,json_file,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = [1,2,3]\n",
    "datasets = ['tvsum','summe']\n",
    "settings = ['tran','aug','can']\n",
    "aug_types = ['Flip','Intrashot','Neighbour','ShotShuf']\n",
    "data_aug = {'Flip':'Flip','Intrashot':'IntraShotShuffle','Neighbour':'ShuffleNeighbourShots','ShotShuf':'ShuffleShots'}\n",
    "for aug_type in aug_types:    \n",
    "    for model in ['PGL_SUM','VASNetPC']:\n",
    "        for dataset in datasets:\n",
    "            for setting in settings:\n",
    "                name = f'{aug_type}_deter_{setting}'\n",
    "                config_path = os.path.join(f'Configs/ShuffleExperiments//{aug_type}',setting)\n",
    "                for trial in trial_number:\n",
    "                    shuff_len_flip = {data_aug[aug_type]:{\"probability\":0.0}}\n",
    "                    config_dict = {\n",
    "                        \"split\" : f\"{dataset}_{setting}_{trial}.json\",\n",
    "                        \"datapath\": f\"eccv16_dataset_{dataset}_google_pool5\",\n",
    "                        \"save_name\": f\"{name}_{trial}\",\n",
    "                        \"reg\": 1e-05,\n",
    "                        \"num_epochs\": 50,\n",
    "                        \"learning_rate\": 5e-05,\n",
    "                        \"Model_params\": {\n",
    "                            \"Model\": model\n",
    "                        },\n",
    "                        \"loss_function\" : \"MSE\",\n",
    "                        \"total_splits\": 5,\n",
    "                        \"data_aug\": shuff_len_flip\n",
    "                    }\n",
    "                    path_save = os.path.join(config_path,model.lower()+f\"_{name}_{dataset}_{trial}.json\")\n",
    "                    with open(path_save,'w') as json_file:\n",
    "                        json.dump(config_dict,json_file,indent=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
